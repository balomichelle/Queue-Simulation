{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and simulate a bank branch\n",
    "\n",
    "## The goal\n",
    "\n",
    "Decrease the number of reneging customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install ```SimPy```\n",
    "```\n",
    "pip install -U simpy\n",
    "```\n",
    "\n",
    "## Develop a model\n",
    "\n",
    "### Step 1: One customer arriving at a fixed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 5.00 \tKalle \tHere I am\n",
      "t: 15.00 \tKalle \tI must leave\n"
     ]
    }
   ],
   "source": [
    "import simpy\n",
    "\n",
    "# Model components\n",
    "#-------------------------------------- \n",
    "def customer(env, name, time_in_bank):                          \n",
    "    print('t: %1.2f \\t%s \\tHere I am' % (env.now, name))\n",
    "    yield env.timeout(time_in_bank)\n",
    "    print('t: %1.2f \\t%s \\tI must leave' % (env.now, name)) \n",
    "\n",
    "# Experiment parameters\n",
    "#--------------------------------------\n",
    "max_time = 100.0     # minutes                            \n",
    "time_in_bank = 10.0   # minutes\n",
    "\n",
    "# Simulation/Experiment\n",
    "#--------------------------------------\n",
    "env = simpy.Environment(initial_time=5.0)\n",
    "proc = env.process(customer(env, 'Kalle', time_in_bank))\n",
    "# Start processes\n",
    "env.run(until=max_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: One customer arriving at a random time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:   4.876 Kalle \tHere I am\n",
      "t:  14.876 Kalle \tI must leave\n"
     ]
    }
   ],
   "source": [
    "import simpy\n",
    "import random\n",
    "\n",
    "\n",
    "# Model components\n",
    "#-------------------------------------- \n",
    "def customer(env,name, time_in_bank):                          \n",
    "    print('t: %7.3f %s \\tHere I am' % (env.now, name))\n",
    "    yield env.timeout(time_in_bank)\n",
    "    print('t: %7.3f %s \\tI must leave' % (env.now, name))  \n",
    "\n",
    "# Experiment parameters\n",
    "#--------------------------------------\n",
    "max_time = 100.0     # minutes                            \n",
    "time_in_bank = 10.0   # minutes\n",
    "\n",
    "# Simulation/Experiment\n",
    "#--------------------------------------\n",
    "random.seed(5)    \n",
    "t = random.expovariate(1.0/5.0)                               \n",
    "env = simpy.Environment(initial_time=t)\n",
    "proc = env.process(customer(env, 'Kalle', time_in_bank))\n",
    "# Start processes\n",
    "env.run(until=max_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detour -- ```random.expovariate()?```\n",
    "Random values from some kind of distribution.\n",
    "\n",
    "##### Question\n",
    "How does this distribution look?\n",
    "Answer: Plot the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1890.7875)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "# Exponential distribution. lambd is 1.0 divided by the desired mean.\n",
    "\n",
    "desired_mean = 5.0\n",
    "\n",
    "t = np.empty(10000)\n",
    "for i in range(t.shape[0]):\n",
    "    t[i] = random.expovariate(1.0 / desired_mean) \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(t, 50)\n",
    "ax.set_xlabel('Time')\n",
    "ylim = ax.get_ylim()\n",
    "ax.plot([desired_mean, desired_mean], ylim, 'r')\n",
    "ax.set_ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Multiple randomly arriving customers\n",
    "\n",
    "The times between customer arrivals are distributed as exponential random variates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank renege\n",
      "t:   0.000 Customer00 \tHere I am\n",
      "t:  10.000 Customer00 \tI must leave\n",
      "t:  15.767 Customer01 \tHere I am\n",
      "t:  25.767 Customer01 \tI must leave\n",
      "t:  33.024 Customer02 \tHere I am\n",
      "t:  39.660 Customer03 \tHere I am\n",
      "t:  42.693 Customer04 \tHere I am\n",
      "t:  43.024 Customer02 \tI must leave\n",
      "t:  49.660 Customer03 \tI must leave\n",
      "t:  52.693 Customer04 \tI must leave\n"
     ]
    }
   ],
   "source": [
    "import simpy\n",
    "import random\n",
    "\n",
    "\n",
    "# Model components\n",
    "#-------------------------------------- \n",
    "def source(env, number, interval, time_in_bank):\n",
    "    \"\"\"Source generates customers randomly\"\"\"\n",
    "    for i in range(number):\n",
    "        c = customer(env, 'Customer%02d' % i, time_in_bank=time_in_bank)\n",
    "        env.process(c)\n",
    "        t = random.expovariate(1.0 / interval)\n",
    "        yield env.timeout(t)\n",
    "        \n",
    "def customer(env,name, time_in_bank):                          \n",
    "    print('t: %7.3f %s \\tHere I am' % (env.now, name))\n",
    "    yield env.timeout(time_in_bank)\n",
    "    print('t: %7.3f %s \\tI must leave' % (env.now, name))  \n",
    "\n",
    "# Experiment parameters\n",
    "#--------------------------------------\n",
    "time_in_bank = 12.0\n",
    "max_time = 400.0     # minutes                              \n",
    "tot_customers = 5    # total number of customers\n",
    "customer_interval = 10.0  # Generate new customers roughly every x min\n",
    "\n",
    "\n",
    "# Simulation/Experiment\n",
    "#--------------------------------------\n",
    "print('Bank renege')\n",
    "random.seed(6)\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Start processes and run\n",
    "counter = simpy.Resource(env, capacity=1)\n",
    "env.process(source(env, tot_customers, customer_interval, time_in_bank))\n",
    "env.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This bank has customers, but something is missing. What?**\n",
    "\n",
    "### Step 4: a service counter\n",
    "The customers are going to require service from the bank clerk.\n",
    "\n",
    "This example models a bank counter and customers arriving *t* random times. Each customer has a certain patience. It waits to get to the counter until she’s at the end of her tether and then leaves. If she gets to the counter, she uses it for a while before releasing it.\n",
    "\n",
    "We extend the model to include a service counter which will be modelled as an object of SimPy’s ```Resource``` class with a single resource unit. The actions of a ```Resource``` are simple: a customer requests a unit of the resource (i.e. a clerk). If it is free the customer gets service (and removes the unit). If it is not free clerk the customer joins the queue (managed by the resource object) until it is their turn to be served.\n",
    "\n",
    "\n",
    "#### One service counter\n",
    "A counter with a random service time and customers who renege."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank renege\n",
      "   0.00 Customer00: Here I am\n",
      "   0.00 Customer00: Waited  0.000\n",
      "   9.65 Customer00: Finished\n",
      "  10.20 Customer01: Here I am\n",
      "  10.20 Customer01: Waited  0.000\n",
      "  12.73 Customer02: Here I am\n",
      "  13.90 Customer02: RENEGED after  1.174\n",
      "  35.00 Customer03: Here I am\n",
      "  36.06 Customer03: RENEGED after  1.060\n",
      "  40.48 Customer04: Here I am\n",
      "  42.49 Customer04: RENEGED after  2.011\n",
      "  44.08 Customer01: Finished\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import simpy\n",
    "\n",
    "\n",
    "# Model components\n",
    "#-------------------------------------- \n",
    "def source(env, number, interval, counter, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Source generates customers randomly\"\"\"\n",
    "    for i in range(number):\n",
    "        c = customer(env, 'Customer%02d' % i, counter, time_at_counter, min_patience, max_patience)\n",
    "        env.process(c)\n",
    "        t = random.expovariate(1.0 / interval)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "\n",
    "def customer(env, name, counter, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Customer arrives, is served and leaves.\"\"\"\n",
    "    arrive = env.now\n",
    "    print('%7.2f %s: Here I am' % (arrive, name))\n",
    "\n",
    "    with counter.request() as req:\n",
    "        patience = random.uniform(min_patience, max_patience)\n",
    "        # Wait for the counter or abort at the end of our tether\n",
    "        results = yield req | env.timeout(patience)\n",
    "\n",
    "        wait = env.now - arrive\n",
    "\n",
    "        if req in results:\n",
    "            # We got to the counter\n",
    "            print('%7.2f %s: Waited %6.3f' % (env.now, name, wait))\n",
    "\n",
    "            tib = random.expovariate(1.0 / time_at_counter)\n",
    "            yield env.timeout(tib)\n",
    "            print('%7.2f %s: Finished' % (env.now, name))\n",
    "\n",
    "        else:\n",
    "            # We reneged\n",
    "            print('%7.2f %s: RENEGED after %6.3f' % (env.now, name, wait))\n",
    "\n",
    "            \n",
    "# Experiment parameters\n",
    "#-------------------------------------- \n",
    "time_at_counter = 25.0  # minutes                              \n",
    "max_time = 400.0     # minutes                              \n",
    "tot_customers = 5    # total number of customers\n",
    "customer_interval = 10.0  # Generate new customers roughly every x min\n",
    "min_patience = 1.    # Min. customer patience\n",
    "max_patience = 3.    # Max. customer patience\n",
    "\n",
    "\n",
    "# Simulation/Experiment\n",
    "#--------------------------------------\n",
    "print('Bank renege')\n",
    "random.seed(42)\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Start processes and run\n",
    "counter = simpy.Resource(env, capacity=1)\n",
    "env.process(source(env, tot_customers, customer_interval, counter, time_at_counter, min_patience, max_patience))\n",
    "env.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple service counters\n",
    "\n",
    "Multiple service counters with a random service time and customers who renege.\n",
    "**But, how will customers queue?**\n",
    "* All in one queue?\n",
    "* Multiple parallel queues?\n",
    "* Or, completely anarchistically, switch between multiple parallel queues?\n",
    "\n",
    "##### Two counters with one shared queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank renege\n",
      "   0.00 Customer00: Here I am\n",
      "   0.00 Customer00: Waited  0.000\n",
      "   8.04 Customer00: Finished\n",
      "  10.20 Customer01: Here I am\n",
      "  10.20 Customer01: Waited  0.000\n",
      "  12.73 Customer02: Here I am\n",
      "  12.73 Customer02: Waited  0.000\n",
      "  26.43 Customer02: Finished\n",
      "  35.00 Customer03: Here I am\n",
      "  35.00 Customer03: Waited  0.000\n",
      "  35.30 Customer04: Here I am\n",
      "  36.70 Customer04: RENEGED after  1.398\n",
      "  38.43 Customer01: Finished\n",
      "  52.60 Customer03: Finished\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import simpy\n",
    "\n",
    "\n",
    "# Model components\n",
    "#-------------------------------------- \n",
    "def source(env, number, interval, counter, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Source generates customers randomly\"\"\"\n",
    "    for i in range(number):\n",
    "        c = customer(env, 'Customer%02d' % i, counter, time_at_counter, min_patience, max_patience)\n",
    "        env.process(c)\n",
    "        t = random.expovariate(1.0 / interval)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "\n",
    "def customer(env, name, counter, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Customer arrives, is served and leaves.\"\"\"\n",
    "    arrive = env.now\n",
    "    print('%7.2f %s: Here I am' % (arrive, name))\n",
    "\n",
    "    with counter.request() as req:\n",
    "        patience = random.uniform(min_patience, max_patience)\n",
    "        # Wait for the counter or abort at the end of our tether\n",
    "        results = yield req | env.timeout(patience)\n",
    "\n",
    "        wait = env.now - arrive\n",
    "\n",
    "        if req in results:\n",
    "            # We got to the counter\n",
    "            print('%7.2f %s: Waited %6.3f' % (env.now, name, wait))\n",
    "\n",
    "            tib = random.expovariate(1.0 / time_at_counter)\n",
    "            yield env.timeout(tib)\n",
    "            print('%7.2f %s: Finished' % (env.now, name))\n",
    "\n",
    "        else:\n",
    "            # We reneged\n",
    "            print('%7.2f %s: RENEGED after %6.3f' % (env.now, name, wait))\n",
    "\n",
    "            \n",
    "# Experiment parameters\n",
    "#-------------------------------------- \n",
    "time_at_counter = 25.0  # minutes                              \n",
    "max_time = 400.0     # minutes                              \n",
    "tot_customers = 5    # total number of customers\n",
    "customer_interval = 10.0  # Generate new customers roughly every x min\n",
    "min_patience = 1.    # Min. customer patience\n",
    "max_patience = 3.    # Max. customer patience\n",
    "\n",
    "\n",
    "# Simulation/Experiment\n",
    "#--------------------------------------\n",
    "print('Bank renege')\n",
    "random.seed(42)\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Start processes and run\n",
    "counter = simpy.Resource(env, capacity=2)\n",
    "env.process(source(env, tot_customers, customer_interval, counter, time_at_counter, min_patience, max_patience))\n",
    "env.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Several counters with individual queues\n",
    "\n",
    "Each customer choses to join the shortest queue.\n",
    "\n",
    "###### Question\n",
    "**How can we model this situation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank renege\n",
      "   0.00 Customer00: Here I am, queue lengths: [0, 0]\n",
      "   0.00 Customer00: Waited  0.000\n",
      "   8.04 Customer00: Finished\n",
      "  10.20 Customer01: Here I am, queue lengths: [0, 0]\n",
      "  10.20 Customer01: Waited  0.000\n",
      "  12.73 Customer02: Here I am, queue lengths: [1, 0]\n",
      "  12.73 Customer02: Waited  0.000\n",
      "  26.43 Customer02: Finished\n",
      "  35.00 Customer03: Here I am, queue lengths: [1, 0]\n",
      "  35.00 Customer03: Waited  0.000\n",
      "  35.30 Customer04: Here I am, queue lengths: [1, 1]\n",
      "  36.70 Customer04: RENEGED after  1.398\n",
      "  38.43 Customer01: Finished\n",
      "  52.60 Customer03: Finished\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import simpy\n",
    "\n",
    "\n",
    "# Model components\n",
    "#-------------------------------------- \n",
    "def source(env, number, interval, counters, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Source generates customers randomly\"\"\"\n",
    "    for i in range(number):\n",
    "        c = customer(env, 'Customer%02d' % i, counters, time_at_counter, min_patience, max_patience)\n",
    "        env.process(c)\n",
    "        t = random.expovariate(1.0 / interval)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "\n",
    "def customer(env, name, counters, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Customer arrives, is served and leaves.\"\"\"\n",
    "    arrive = env.now\n",
    "    \n",
    "    # get queue lengths\n",
    "    q_lens = [c.count for c in counters]\n",
    "    print('%7.2f %s: Here I am, queue lengths: %s' % (arrive, name, q_lens))\n",
    "    \n",
    "    # chose the shortest queue\n",
    "    choice = q_lens.index(min(q_lens))\n",
    "\n",
    "    with counters[choice].request() as req:\n",
    "        patience = random.uniform(min_patience, max_patience)\n",
    "        # Wait for the counter or abort at the end of our tether\n",
    "        results = yield req | env.timeout(patience)\n",
    "\n",
    "        wait = env.now - arrive\n",
    "\n",
    "        if req in results:\n",
    "            # We got to the counter\n",
    "            print('%7.2f %s: Waited %6.3f' % (env.now, name, wait))\n",
    "\n",
    "            tib = random.expovariate(1.0 / time_at_counter)\n",
    "            yield env.timeout(tib)\n",
    "            print('%7.2f %s: Finished' % (env.now, name))\n",
    "\n",
    "        else:\n",
    "            # We reneged\n",
    "            print('%7.2f %s: RENEGED after %6.3f' % (env.now, name, wait))\n",
    "            \n",
    "            \n",
    "# Experiment parameters\n",
    "#-------------------------------------- \n",
    "time_at_counter = 25.0  # minutes                              \n",
    "max_time = 400.0     # minutes                              \n",
    "tot_customers = 5    # total number of customers\n",
    "customer_interval = 10.0  # Generate new customers roughly every x min\n",
    "min_patience = 1.    # Min. customer patience\n",
    "max_patience = 3.    # Max. customer patience\n",
    "\n",
    "\n",
    "# Simulation/Experiment\n",
    "#--------------------------------------\n",
    "print('Bank renege')\n",
    "random.seed(42)\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Start processes and run\n",
    "counters = [simpy.Resource(env, capacity=1), simpy.Resource(env, capacity=1)]\n",
    "env.process(source(env, tot_customers, customer_interval, counters, time_at_counter, min_patience, max_patience))\n",
    "env.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of model building**\n",
    "\n",
    "We got ourselves a model.\n",
    "\n",
    "However, something is missing... Can we really use this for decision making?\n",
    "\n",
    "## Sample from our model\n",
    "\n",
    "We need to get some data we can generalize from. That is, we need to gather data from longer and multiple runs.\n",
    "\n",
    "### Questions\n",
    "* How to sample?\n",
    "* How to collect data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average wait time for 10000 customers was 0.949 min and 45.9% reneged\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import simpy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Model components\n",
    "#-------------------------------------- \n",
    "data = {'wait': [], 'reneg': []}\n",
    "\n",
    "def source(env, number, interval, counters, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Source generates customers randomly\"\"\"\n",
    "    for i in range(number):\n",
    "        c = customer(env, 'Customer%02d' % i, counters, time_at_counter, min_patience, max_patience)\n",
    "        env.process(c)\n",
    "        t = random.expovariate(1.0 / interval)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "\n",
    "def customer(env, name, counters, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Customer arrives, is served and leaves.\"\"\"\n",
    "    arrive = env.now\n",
    "    \n",
    "    # get queue lengths\n",
    "    q_lens = [c.count for c in counters]    \n",
    "    # chose the shortest queue\n",
    "    choice = q_lens.index(min(q_lens))\n",
    "\n",
    "    with counters[choice].request() as req:\n",
    "        patience = random.uniform(min_patience, max_patience)\n",
    "        # Wait for the counter or abort at the end of our tether\n",
    "        results = yield req | env.timeout(patience)\n",
    "\n",
    "        wait = env.now - arrive\n",
    "        data['wait'].append(wait)  # data is declared above, in the global scope\n",
    "\n",
    "        if req in results:\n",
    "            tib = random.expovariate(1.0 / time_at_counter)\n",
    "            data['reneg'].append(False)\n",
    "            yield env.timeout(tib)\n",
    "        else:\n",
    "            # We reneged\n",
    "            data['reneg'].append(True)\n",
    "            \n",
    "            \n",
    "# Experiment parameters\n",
    "#-------------------------------------- \n",
    "time_at_counter = 25.0  # minutes                              \n",
    "max_time = 400.0     # minutes                              \n",
    "tot_customers = 10000    # total number of customers\n",
    "customer_interval = 10.0  # Generate new customers roughly every x min\n",
    "min_patience = 1.    # Min. customer patience\n",
    "max_patience = 3.    # Max. customer patience\n",
    "\n",
    "\n",
    "# Simulation/Experiment\n",
    "#--------------------------------------\n",
    "random.seed(42)\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Start processes and run\n",
    "counters = [simpy.Resource(env, capacity=1), simpy.Resource(env, capacity=1)]\n",
    "env.process(source(env, tot_customers, customer_interval, counters, time_at_counter, min_patience, max_patience))\n",
    "env.run()\n",
    "\n",
    "reneg = np.array(data['reneg'])\n",
    "wait_times = np.array(data['wait'])\n",
    "print('Average wait time for %d customers was %1.3f min and %1.1f%% reneged' % (tot_customers, wait_times.mean(), 100 * reneg.sum()/tot_customers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions, decisions...\n",
    "\n",
    "### We got a problem\n",
    "\n",
    "**Too many customers reneg, but we cannot employ more clerks. What should we do?**\n",
    "\n",
    "Maybe customers get tired legs.\n",
    "\n",
    "Get a sofa!!\n",
    "\n",
    "\n",
    "#### Question\n",
    "**How would we model the effects of a sofa?**\n",
    "\n",
    "Answer: increase patience\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average wait time for 1000 customers was 8.862 min and 41.2% reneged\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import simpy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Model components\n",
    "#-------------------------------------- \n",
    "data = {'wait': [], 'reneg': [], 'tib': []}\n",
    "\n",
    "def source(env, number, interval, counters, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Source generates customers randomly\"\"\"\n",
    "    for i in range(number):\n",
    "        c = customer(env, 'Customer%02d' % i, counters, time_at_counter, min_patience, max_patience)\n",
    "        env.process(c)\n",
    "        t = random.expovariate(1.0 / interval)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "\n",
    "def customer(env, name, counters, time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Customer arrives, is served and leaves.\"\"\"\n",
    "    arrive = env.now\n",
    "    \n",
    "    # get queue lengths\n",
    "    q_lens = [c.count for c in counters]    \n",
    "    # chose the shortest queue\n",
    "    choice = q_lens.index(min(q_lens))\n",
    "\n",
    "    with counters[choice].request() as req:\n",
    "        patience = random.uniform(min_patience, max_patience)\n",
    "        # Wait for the counter or abort at the end of our tether\n",
    "        results = yield req | env.timeout(patience)\n",
    "\n",
    "        wait = env.now - arrive\n",
    "        data['wait'].append(wait)  # data is declared above, in the global scope\n",
    "\n",
    "        if req in results:\n",
    "            tib = random.expovariate(1.0 / time_at_counter)\n",
    "            data['reneg'].append(False)\n",
    "            data['tib'].append(tib)\n",
    "            yield env.timeout(tib)\n",
    "        else:\n",
    "            # We reneged\n",
    "            data['reneg'].append(True)\n",
    "            data['tib'].append(-1)\n",
    "            \n",
    "            \n",
    "# Experiment parameters\n",
    "#-------------------------------------- \n",
    "time_at_counter = 25.0  # minutes                              \n",
    "max_time = 400.0     # minutes                              \n",
    "tot_customers = 1000    # total number of customers\n",
    "customer_interval = 10.0  # Generate new customers roughly every x min\n",
    "min_patience = 5.    # Min. customer patience\n",
    "max_patience = 30.    # Max. customer patience\n",
    "\n",
    "\n",
    "# Simulation/Experiment\n",
    "#--------------------------------------\n",
    "random.seed(42)\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Start processes and run\n",
    "counters = [simpy.Resource(env, capacity=1), simpy.Resource(env, capacity=1)]\n",
    "env.process(source(env, tot_customers, customer_interval, counters, time_at_counter, min_patience, max_patience))\n",
    "env.run()\n",
    "\n",
    "reneg = np.array(data['reneg'])\n",
    "wait_times = np.array(data['wait'])\n",
    "print('Average wait time for %d customers was %1.3f min and %1.1f%% reneged' % (tot_customers, wait_times.mean(), 100 * reneg.sum()/tot_customers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other improvements?**\n",
    "\n",
    "How about training the clerks so that they can help the customers faster?\n",
    "\n",
    "#### Question\n",
    "**How could we model faster clerks?**\n",
    "\n",
    "Answer: Decrease average time at counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average wait time for 1000 customers was 0.573 min and 26.3% reneged\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import simpy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Model components\n",
    "#-------------------------------------- \n",
    "data = {'wait': [], 'reneg': [], 'tib': []}\n",
    "\n",
    "def source(env, number, interval, counters, ave_time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Source generates customers randomly\"\"\"\n",
    "    for i in range(number):\n",
    "        c = customer(env, 'Customer%02d' % i, counters, ave_time_at_counter, min_patience, max_patience)\n",
    "        env.process(c)\n",
    "        t = random.expovariate(1.0 / interval)\n",
    "        yield env.timeout(t)\n",
    "\n",
    "\n",
    "def customer(env, name, counters, ave_time_at_counter, min_patience, max_patience):\n",
    "    \"\"\"Customer arrives, is served and leaves.\"\"\"\n",
    "    arrive = env.now\n",
    "    \n",
    "    # get queue lengths\n",
    "    q_lens = [c.count for c in counters]    \n",
    "    # chose the shortest queue\n",
    "    choice = q_lens.index(min(q_lens))\n",
    "\n",
    "    with counters[choice].request() as req:\n",
    "        patience = random.uniform(min_patience, max_patience)\n",
    "        # Wait for the counter or abort at the end of our tether\n",
    "        results = yield req | env.timeout(patience)\n",
    "\n",
    "        wait = env.now - arrive\n",
    "        data['wait'].append(wait)  # data is declared above, in the global scope\n",
    "\n",
    "        if req in results:\n",
    "            tib = random.expovariate(1.0 / ave_time_at_counter)\n",
    "            data['reneg'].append(False)\n",
    "            data['tib'].append(tib)\n",
    "            yield env.timeout(tib)\n",
    "        else:\n",
    "            # We reneged\n",
    "            data['reneg'].append(True)\n",
    "            data['tib'].append(-1)\n",
    "            \n",
    "            \n",
    "# Experiment parameters\n",
    "#-------------------------------------- \n",
    "ave_time_at_counter = 15.0  # minutes                              \n",
    "max_time = 400.0     # minutes                              \n",
    "tot_customers = 1000    # total number of customers\n",
    "customer_interval = 10.0  # Generate new customers roughly every x min\n",
    "min_patience = 1.    # Min. customer patience\n",
    "max_patience = 3.    # Max. customer patience\n",
    "\n",
    "\n",
    "# Simulation/Experiment\n",
    "#--------------------------------------\n",
    "random.seed(42)\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Start processes and run\n",
    "counters = [simpy.Resource(env, capacity=1), simpy.Resource(env, capacity=1)]\n",
    "env.process(source(env, tot_customers, customer_interval, counters, ave_time_at_counter, min_patience, max_patience))\n",
    "env.run()\n",
    "\n",
    "reneg = np.array(data['reneg'])\n",
    "wait_times = np.array(data['wait'])\n",
    "print('Average wait time for %d customers was %1.3f min and %1.1f%% reneged' % (tot_customers, wait_times.mean(), 100 * reneg.sum()/tot_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "tib = np.array(data['tib'])\n",
    "tib = tib[tib > -1]\n",
    "\n",
    "plt.hist(tib, 20)\n",
    "plt.xlabel('Time at counter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
